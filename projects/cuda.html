<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Optimisation CUDA - Ornela Portfolio</title>
    <link rel="stylesheet" href="../css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body class="project-cuda">
    <!-- Navigation -->
    <nav class="navbar">
        <div class="container">
            <div class="nav-brand">
                <a href="../index.html"><h2>‚Üê Retour au Portfolio</h2></a>
            </div>
        </div>
    </nav>

    <!-- Hero du Projet -->
    <section class="project-hero">
        <div class="container">
            <h1>Optimisation de Multiplication Matricielle en CUDA</h1>
            <p class="project-meta">Laboratoire GPU Computing ‚Ä¢ CUDA C++ ‚Ä¢ 2024</p>
            <div class="project-links">
                <a href="https://github.com/ornel237" class="btn btn-primary" target="_blank">
                    <i class="fab fa-github"></i> Voir sur GitHub
                </a>
            </div>
        </div>
    </section>

    <!-- D√©tails du Projet -->
    <section class="project-details">
        <div class="container">
            <!-- Vue d'ensemble -->
            <div class="detail-section">
                <h2><i class="fas fa-info-circle"></i> Vue d'ensemble</h2>
                <p>
                    D√©veloppement et optimisation progressive de kernels CUDA pour la multiplication de matrices sur GPU. 
                    Le projet explore diff√©rentes techniques d'optimisation, de l'impl√©mentation na√Øve jusqu'√† des versions 
                    hautement optimis√©es utilisant la m√©moire partag√©e, le tiling, et la coalescence m√©moire. L'objectif est 
                    de d√©montrer les gains de performances massifs obtenus par l'application syst√©matique de techniques 
                    d'optimisation GPU pour le calcul haute performance (HPC).
                </p>
            </div>

            <!-- Contexte -->
            <div class="detail-section">
                <h2><i class="fas fa-graduation-cap"></i> Contexte</h2>
                <ul>
                    <li><strong>Cours :</strong> Programmation GPU et Calcul Parall√®le - UQTR</li>
                    <li><strong>Mat√©riel :</strong> GPU NVIDIA (Compute Capability 7.0+)</li>
                    <li><strong>Environnement :</strong> CUDA Toolkit 11.x / 12.x</li>
                    <li><strong>Dur√©e :</strong> S√©rie de laboratoires (6 semaines)</li>
                    <li><strong>Objectif :</strong> Ma√Ætriser l'optimisation GPU et atteindre les performances th√©oriques</li>
                </ul>
            </div>

            <!-- Fonctionnalit√©s -->
            <div class="detail-section">
                <h2><i class="fas fa-list-check"></i> Versions impl√©ment√©es</h2>
                <div class="features-grid">
                    <div class="feature-item">
                        <i class="fas fa-layer-group"></i>
                        <h3>Version 1 : Na√Øve</h3>
                        <p>Impl√©mentation de base avec un thread par √©l√©ment de sortie</p>
                    </div>
                    <div class="feature-item">
                        <i class="fas fa-memory"></i>
                        <h3>Version 2 : M√©moire globale</h3>
                        <p>Optimisation des acc√®s m√©moire avec coalescence</p>
                    </div>
                    <div class="feature-item">
                        <i class="fas fa-th"></i>
                        <h3>Version 3 : Tiling basique</h3>
                        <p>D√©coupage en tuiles pour r√©utiliser les donn√©es</p>
                    </div>
                    <div class="feature-item">
                        <i class="fas fa-rocket"></i>
                        <h3>Version 4 : Shared Memory</h3>
                        <p>Utilisation de la m√©moire partag√©e rapide pour les tuiles</p>
                    </div>
                    <div class="feature-item">
                        <i class="fas fa-tachometer-alt"></i>
                        <h3>Version 5 : Optimis√©e</h3>
                        <p>Combinaison de toutes les techniques + bank conflict resolution</p>
                    </div>
                    <div class="feature-item">
                        <i class="fas fa-chart-line"></i>
                        <h3>Analyse de performances</h3>
                        <p>Benchmarking complet avec nvprof/nsight et comparaisons CPU</p>
                    </div>
                </div>
            </div>

            <!-- Architecture technique -->
            <div class="detail-section">
                <h2><i class="fas fa-code"></i> Impl√©mentations techniques</h2>
                
                <h3>Version 1 : Kernel na√Øf</h3>
                <pre><code>__global__ void matrixMulNaive(float *A, float *B, float *C, int N) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (row < N && col < N) {
        float sum = 0.0f;
        for (int k = 0; k < N; k++) {
            sum += A[row * N + k] * B[k * N + col];
        }
        C[row * N + col] = sum;
    }
}</code></pre>

                <h3>Version 4 : Avec m√©moire partag√©e et tiling</h3>
                <pre><code>__global__ void matrixMulShared(float *A, float *B, float *C, int N) {
    __shared__ float tileA[TILE_SIZE][TILE_SIZE];
    __shared__ float tileB[TILE_SIZE][TILE_SIZE];
    
    int row = blockIdx.y * TILE_SIZE + threadIdx.y;
    int col = blockIdx.x * TILE_SIZE + threadIdx.x;
    float sum = 0.0f;
    
    // It√©rer sur les tuiles
    for (int t = 0; t < (N + TILE_SIZE - 1) / TILE_SIZE; t++) {
        // Charger les tuiles en m√©moire partag√©e
        if (row < N && t * TILE_SIZE + threadIdx.x < N)
            tileA[threadIdx.y][threadIdx.x] = A[row * N + t * TILE_SIZE + threadIdx.x];
        else
            tileA[threadIdx.y][threadIdx.x] = 0.0f;
            
        if (col < N && t * TILE_SIZE + threadIdx.y < N)
            tileB[threadIdx.y][threadIdx.x] = B[(t * TILE_SIZE + threadIdx.y) * N + col];
        else
            tileB[threadIdx.y][threadIdx.x] = 0.0f;
            
        __syncthreads();
        
        // Calculer le produit partiel
        for (int k = 0; k < TILE_SIZE; k++) {
            sum += tileA[threadIdx.y][k] * tileB[k][threadIdx.x];
        }
        
        __syncthreads();
    }
    
    if (row < N && col < N) {
        C[row * N + col] = sum;
    }
}</code></pre>

                <h3>Configuration de lancement</h3>
                <pre><code>// Configuration des blocs et grille
dim3 blockDim(TILE_SIZE, TILE_SIZE);
dim3 gridDim((N + TILE_SIZE - 1) / TILE_SIZE, 
             (N + TILE_SIZE - 1) / TILE_SIZE);

// Lancement du kernel
matrixMulShared<<<gridDim, blockDim>>>(d_A, d_B, d_C, N);</code></pre>
            </div>

            <!-- D√©fis et solutions -->
            <div class="detail-section">
                <h2><i class="fas fa-lightbulb"></i> D√©fis techniques et solutions</h2>
                <div class="challenge-solution">
                    <div class="challenge">
                        <h3>D√©fi 1 : Acc√®s m√©moire non coalesc√©s</h3>
                        <p>Les acc√®s d√©sordonn√©s √† la m√©moire globale limitent les performances.</p>
                    </div>
                    <div class="solution">
                        <h3>Solution</h3>
                        <p>Restructuration des acc√®s pour assurer la coalescence : threads cons√©cutifs 
                        acc√®dent √† des adresses m√©moire cons√©cutives (stride-1 access).</p>
                    </div>
                </div>

                <div class="challenge-solution">
                    <div class="challenge">
                        <h3>D√©fi 2 : Latence de la m√©moire globale</h3>
                        <p>La m√©moire globale est 100x plus lente que la m√©moire partag√©e.</p>
                    </div>
                    <div class="solution">
                        <h3>Solution</h3>
                        <p>Impl√©mentation de tiling avec m√©moire partag√©e : chaque tuile est charg√©e 
                        une fois et r√©utilis√©e TILE_SIZE fois, r√©duisant les acc√®s globaux.</p>
                    </div>
                </div>

                <div class="challenge-solution">
                    <div class="challenge">
                        <h3>D√©fi 3 : Bank conflicts</h3>
                        <p>Les conflits de bancs m√©moire r√©duisent la bande passante de la m√©moire partag√©e.</p>
                    </div>
                    <div class="solution">
                        <h3>Solution</h3>
                        <p>Padding des tableaux partag√©s et r√©organisation des acc√®s pour √©viter que 
                        plusieurs threads acc√®dent au m√™me banc simultan√©ment.</p>
                    </div>
                </div>
            </div>

            <!-- R√©sultats de performance -->
            <div class="detail-section">
                <h2><i class="fas fa-chart-bar"></i> R√©sultats de performances</h2>
                <h3>Matrices 2048 x 2048 (valeurs typiques)</h3>
                
                <div class="tech-grid">
                    <div class="tech-item">
                        <i class="fas fa-desktop"></i>
                        <span>CPU (1 core) : ~45 secondes</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-desktop"></i>
                        <span>CPU (8 cores) : ~8 secondes</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-microchip"></i>
                        <span>GPU Na√Øf : ~1.2 secondes (37x speedup)</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-memory"></i>
                        <span>GPU avec coalescence : ~0.45s (100x)</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-rocket"></i>
                        <span>GPU + Shared Memory : ~0.085s (530x)</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-fire"></i>
                        <span>GPU Optimis√© : ~0.048s (937x speedup!)</span>
                    </div>
                </div>

                <h3>M√©triques d'optimisation</h3>
                <ul>
                    <li>üìä <strong>Occupation GPU :</strong> 25% ‚Üí 85% (na√Øf ‚Üí optimis√©)</li>
                    <li>üíæ <strong>Bande passante :</strong> 150 GB/s ‚Üí 750 GB/s (95% du th√©orique)</li>
                    <li>‚ö° <strong>GFLOPS :</strong> 200 ‚Üí 4800 GFLOPS</li>
                    <li>üîÑ <strong>R√©duction acc√®s m√©moire globale :</strong> 100% ‚Üí 6% (gr√¢ce au tiling)</li>
                </ul>
            </div>

            <!-- Technologies utilis√©es -->
            <div class="detail-section">
                <h2><i class="fas fa-tools"></i> Technologies et outils</h2>
                <div class="tech-grid">
                    <div class="tech-item">
                        <i class="fab fa-nvidia"></i>
                        <span>CUDA C/C++</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-microchip"></i>
                        <span>NVIDIA GPU (RTX/Tesla)</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-tools"></i>
                        <span>CUDA Toolkit 11+</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-chart-line"></i>
                        <span>nvprof / Nsight Compute</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-terminal"></i>
                        <span>nvcc Compiler</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-code"></i>
                        <span>C++ (host code)</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-vial"></i>
                        <span>cuBLAS (comparison)</span>
                    </div>
                    <div class="tech-item">
                        <i class="fas fa-laptop-code"></i>
                        <span>Visual Studio / Linux</span>
                    </div>
                </div>
            </div>

            <!-- Apprentissages -->
            <div class="detail-section">
                <h2><i class="fas fa-brain"></i> Comp√©tences d√©velopp√©es</h2>
                <ul class="skills-learned">
                    <li>Programmation parall√®le massivement avec CUDA</li>
                    <li>Compr√©hension approfondie de l'architecture GPU (warps, SM, m√©moire)</li>
                    <li>Techniques d'optimisation : tiling, shared memory, coalescence</li>
                    <li>Profilage et analyse de performances avec Nsight</li>
                    <li>Gestion de la hi√©rarchie m√©moire GPU (global, shared, registers)</li>
                    <li>Synchronisation et coordination de threads</li>
                    <li>Calcul haute performance (HPC) et benchmarking</li>
                    <li>Analyse des compromis occupancy vs. ressources</li>
                </ul>
            </div>

            <!-- Techniques avanc√©es -->
            <div class="detail-section">
                <h2><i class="fas fa-rocket"></i> Techniques d'optimisation appliqu√©es</h2>
                <ul>
                    <li>üß© <strong>Tiling (Blocking) :</strong> D√©coupage des matrices pour r√©utiliser les donn√©es</li>
                    <li>üíæ <strong>Shared Memory :</strong> Cache rapide on-chip partag√© entre threads d'un bloc</li>
                    <li>üìê <strong>Memory Coalescence :</strong> Acc√®s m√©moire align√©s et cons√©cutifs</li>
                    <li>üîÑ <strong>Loop Unrolling :</strong> D√©roulage de boucles pour r√©duire les branches</li>
                    <li>‚öñÔ∏è <strong>Occupancy Optimization :</strong> √âquilibrer threads vs. ressources partag√©es</li>
                    <li>üè¶ <strong>Bank Conflict Avoidance :</strong> √âviter les conflits de bancs m√©moire</li>
                    <li>üìä <strong>Grid Stride Pattern :</strong> G√©rer des donn√©es plus grandes que la grille</li>
                    <li>‚è±Ô∏è <strong>Streams & Async :</strong> Overlapping computation et transfers</li>
                </ul>
            </div>

            <!-- Liens -->
            <div class="detail-section cta-section">
                <h2>Explorer le code</h2>
                <p>Code source complet des diff√©rentes versions, scripts de benchmark et documentation.</p>
                <a href="https://github.com/ornel237" class="btn btn-primary" target="_blank">
                    <i class="fab fa-github"></i> Voir sur GitHub
                </a>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2024 Domen Tchuisseu Lucresse Ornela. Tous droits r√©serv√©s.</p>
        </div>
    </footer>
</body>
</html>
